{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision Meets ML Assignment 3 : Hands Action Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "from io import StringIO\n",
    "import csv\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from engine import train_one_epoch, evaluate\n",
    "import utils\n",
    "import transforms as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation and Transformation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Image transformations\n",
    "image_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'valid':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_name_to_index = {'puzzle':0, 'cards':1,'chess':2,'jenga':3}\n",
    "classes = ('puzzle', 'cards', 'chess', 'jenga')\n",
    "image_sequence_list_global = []\n",
    "class_num_to_lst = []\n",
    "index = 0\n",
    "\n",
    "directory = \"image_sequences\"\n",
    "\n",
    "listOfFileNames = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images add masks\n",
    "from torchvision.transforms import functional as F\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "'''\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "\n",
    "model = get_instance_segmentation_model(num_classes)\n",
    "\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load('/scratch/sm8235/py_complete_epoch.pth'))\n",
    "model.eval()\n",
    "threshold = 0.7\n",
    "\n",
    "all_images_list = []\n",
    "count = 0\n",
    "list.sort(image_sequence_list_global)\n",
    "\n",
    "for fileName in image_sequence_list_global:\n",
    "    count += 1\n",
    "    if(count >= 300):\n",
    "        break\n",
    "    currentSequence = fileName\n",
    "    currentClassName = currentSequence.split('_')[0]\n",
    "    currentVideoNum = currentSequence.split('_')[1]\n",
    "    currentSeqNum = currentSequence.split('_')[2]\n",
    "    currentImgFileName = currentClassName + '_' + currentVideoNum + '_' + currentSeqNum + 'image'\n",
    "\n",
    "    all_images_combined = []\n",
    "\n",
    "    for imgNum in range(0,10):\n",
    "        img_path = os.path.join('', \"image_sequences\",currentImgFileName + str(imgNum) + '.jpg')\n",
    "        transforms = get_transform(train=True)\n",
    "        target = {}\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        with torch.autograd.detect_anomaly():\n",
    "            img = image_transforms['train'](img)\n",
    "            #img = F.to_tensor(img)\n",
    "        with torch.no_grad():\n",
    "            prediction = model([torch.tensor(img).to(device)])\n",
    "            maskImage = torch.sum(prediction[0]['masks'][:, 0],dim=0)\n",
    "            outMaskImage = (maskImage>threshold).float()\n",
    "            outMaskImage = outMaskImage.expand(1,-1,-1)\n",
    "            # outMaskImage : H, W\n",
    "            combinedImage = torch.cat([torch.tensor(img).to(device),outMaskImage],dim=0)\n",
    "            combinedImage = combinedImage.expand(1,-1,-1,-1)\n",
    "            all_images_combined.append(combinedImage)\n",
    "            #print(combinedImage.shape)\n",
    "    img = torch.cat(all_images_combined,dim=0)\n",
    "    all_images_list.append(img.to('cpu'))\n",
    "''';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the tensors which were already preprocessed\n",
    "\n",
    "In total we have 864 sequence of 10 frames each for all the videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864\n"
     ]
    }
   ],
   "source": [
    "all_images_list = []\n",
    "for index in range(0,864):\n",
    "    imgTens = torch.load('combined_images_train' + str(index) + '.pt')\n",
    "    all_images_list.append(imgTens)\n",
    "    \n",
    "print(len(all_images_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864\n"
     ]
    }
   ],
   "source": [
    "array_sequence_list = np.load('combined_image_fileNames_train.npy')\n",
    "array_sequence_list_test = np.load('combined_image_fileNames_test.npy')\n",
    "\n",
    "image_sequence_list_global = np.concatenate((array_sequence_list, array_sequence_list_test), axis=None).tolist()\n",
    "print(len(image_sequence_list_global))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the custom dataset for our sequence of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the custom dataset for our sequence of images\n",
    "from torchvision.transforms import functional as F\n",
    "class Hand_Seq_Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root, transforms=None):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        self.image_sequence_list = image_sequence_list_global\n",
    "    def __getitem__(self, idx):\n",
    "        # load images and masks\n",
    "        currentSequence = self.image_sequence_list[idx]\n",
    "        currentClassName = currentSequence.split('_')[0]\n",
    "        #img = torch.load('combined_images_train' + str(idx) + '.pt')\n",
    "        img = all_images_list[idx]\n",
    "        img = img.to(device)\n",
    "        labels = torch.ones((10), dtype=torch.uint8)\n",
    "        labels =  labels.mul(class_name_to_index[currentClassName])\n",
    "        target = {}\n",
    "        target[\"labels\"] = labels\n",
    "        return img, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_sequence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Training Dataloader and Test Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "# use our dataset and defined transformations\n",
    "dataset = Hand_Seq_Dataset('',image_transforms['train'])\n",
    "dataset_test = Hand_Seq_Dataset('',image_transforms['valid'])\n",
    "\n",
    "# split the dataset in train and test set\n",
    "#torch.manual_seed(1)\n",
    "#indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset_1 = torch.utils.data.Subset(dataset, range(0,576))\n",
    "dataset_test_1 = torch.utils.data.Subset(dataset_test, range(576,864))\n",
    "\n",
    "print(len(dataset_1))\n",
    "print(len(dataset_test_1))\n",
    "\n",
    "# define training and validation data loaders\n",
    "data_loader = torch.utils.data.DataLoader(dataset_1, batch_size=4, shuffle=True, num_workers=0,collate_fn=utils.collate_fn)\n",
    "\n",
    "data_loader_test = torch.utils.data.DataLoader(dataset_test_1, batch_size=4, shuffle=False, num_workers=0,collate_fn=utils.collate_fn)\n",
    "classes = ('puzzle', 'cards', 'chess', 'jenga')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the model and adding layers required for hand action classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_Video_Classification(nn.Module):\n",
    "    def __init__(self, sinkhorn_iter=0):\n",
    "        super().__init__()\n",
    "        self.res50_model = models.resnet50(pretrained=True)\n",
    "        for param in self.res50_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.layers =[nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3,bias=False)]\n",
    "        self.layers.extend(list(self.res50_model.children())[1:-1])\n",
    "        self.res50_conv = nn.Sequential(*self.layers)\n",
    "        self.pretrained_resnet = self.res50_conv\n",
    "        self.fc1 = nn.Linear(2048, 400)\n",
    "        self.fc2 = nn.Linear(400, 4)\n",
    "        self.lr = nn.LeakyReLU(0.2,True)\n",
    "        self.sm = nn.Softmax()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Split input into four pieces and pass them into the\n",
    "        # same convolutional neural network.\n",
    "        pre_trained_last = self.pretrained_resnet(x)\n",
    "        pre_trained_last_flatten = pre_trained_last.view(10,-1)\n",
    "        #print(pre_trained_last_flatten)\n",
    "        #pre_trained_last_final = self.conv1(pre_trained_last_flatten)\n",
    "        pre_trained_last_1 = self.lr(self.fc1(pre_trained_last_flatten))\n",
    "        pre_trained_last_final = self.lr(self.fc2(pre_trained_last_1))\n",
    "        return self.sm(pre_trained_last_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below we can see : conv0, fc1, fc2 layers were added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res50_conv.0.weight\n",
      "fc1.weight\n",
      "fc1.bias\n",
      "fc2.weight\n",
      "fc2.bias\n"
     ]
    }
   ],
   "source": [
    "net = Net_Video_Classification()\n",
    "for param in net.named_parameters():\n",
    "    if(param[1].requires_grad == True):\n",
    "        print(param[0])\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Script for each training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(inputs, labels, optimizer, criterion, unet):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = unet(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the optimizer and the criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "learning_rate  = 0.001\n",
    "network_momentum = 0.99\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr = learning_rate, momentum = network_momentum)\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model for 20 epochs and save the .pth files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from matplotlib import pyplot as plt\n",
    "epochs = 10\n",
    "t = trange(epochs, leave=True)\n",
    "net.train()\n",
    "\n",
    "for iter in t:\n",
    "    total_loss = 0\n",
    "    for index, data in enumerate(data_loader):\n",
    "        img,labels = data\n",
    "        labels = labels[0].long().to(device)\n",
    "        img = image_transforms['train'](img)\n",
    "        inp=img[0].to(device)\n",
    "\n",
    "        with torch.autograd.detect_anomaly():        \n",
    "            batch_loss = train_step(inp, labels, optimizer, criterion, net)\n",
    "            total_loss += batch_loss\n",
    "    print(\"\\n\\n\\n******** total_epoch_training_loss = \" + str(total_loss/len(data_loader))+\" ********\\n\\n\\n\")\n",
    "    PATH = '/scratch/sm8235/resnet_saved/1saved_' + str(iter) + '_l_' + str(total_loss/len(data_loader)) +  '.pth'\n",
    "    torch.save(net.state_dict(),PATH)\n",
    "PATH = '/scratch/sm8235/resnet_saved/1final_10epoch.pth'\n",
    "torch.save(net.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the test step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(inputs, labels, optimizer, criterion, unet):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = unet(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    print(loss)\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0\n",
    "for index, data in enumerate(data_loader_test):\n",
    "    img,labels = data\n",
    "    labels = labels[0].long().to(device)\n",
    "    inp=img[0].to(device)\n",
    "    with torch.autograd.detect_anomaly():        \n",
    "        outputs_test = test_step(inp , labels, optimizer, criterion, net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of ResNet50 model on the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in data_loader_test:\n",
    "        images, labels = data\n",
    "        outputs = net(images[0])\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels[0].size(0)\n",
    "        label = labels[0].to(device)\n",
    "        predicted = predicted.to(device)\n",
    "        correct += (predicted == label).sum().item()\n",
    "\n",
    "print('Accuracy of the network on all 16 Test Set videos: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2 : vgg16 net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch import optim\n",
    "model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Freeze model weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "n_classes = 4\n",
    "import torch.nn as nn\n",
    "# Add on classifier\n",
    "model.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(4096, 256), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, n_classes),                   \n",
    "                      nn.LogSoftmax(dim=1))\n",
    "model = model.to('cuda')\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for training the model for 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "n_epochs = 20\n",
    "total_loss = 0\n",
    "t = trange(n_epochs, leave=True)\n",
    "for epoch in t:\n",
    "    total_loss = 0\n",
    "    for data, targets in data_loader:\n",
    "        # Generate predictions\n",
    "        targets = targets[0].long().to(device)\n",
    "        data=data[0].to(device)\n",
    "        out = model(data[:,:3])\n",
    "        # Calculate loss\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(out, targets)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Update model parameters\n",
    "        optimizer.step()      \n",
    "        total_loss += loss\n",
    "    print(\"\\n\\n\\n******** total_epoch_training_loss = \" + str(total_loss/len(data_loader))+\" ********\\n\\n\\n\")\n",
    "    PATH = '/scratch/sm8235/vggnet_saved/saved_' + str(iter) + '_l_' + str(total_loss/len(data_loader)) +  '.pth'\n",
    "    torch.save(net.state_dict(),PATH)\n",
    "PATH = '/scratch/sm8235/vggnet_saved/final_20epoch.pth'\n",
    "torch.save(net.state_dict(),PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking some of the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.max(\n",
      "values=tensor([0.9223, 0.6898, 0.7316, 0.5071, 0.6697, 0.5416, 0.6048, 0.5391, 0.7374,\n",
      "        0.9839], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 1, 3, 3, 3, 2, 3, 3, 3], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.3820, 0.4460, 0.8767, 0.7428, 0.7754, 0.4869, 0.8425, 0.6347, 0.5438,\n",
      "        0.8531], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 3, 1, 1, 1, 2, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7859, 0.9137, 0.9994, 0.9997, 0.9428, 0.7199, 0.9989, 0.9990, 0.4607,\n",
      "        0.9309], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 1, 1, 1, 1, 1, 1, 1, 3, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9711, 0.9877, 0.8811, 0.9872, 0.9696, 0.9738, 0.9857, 0.9905, 0.8452,\n",
      "        0.9083], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 2, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9406, 0.7377, 0.5713, 0.9348, 0.9690, 0.8928, 0.8259, 0.8989, 0.7938,\n",
      "        0.9631], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 0, 1, 1, 1, 3, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8394, 0.6618, 0.6027, 0.9077, 0.8183, 0.8643, 0.8942, 0.5618, 0.7202,\n",
      "        0.9246], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 3, 0, 1, 0, 1, 1, 0, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.6208, 0.6050, 0.8465, 0.7601, 0.7712, 0.9459, 0.5656, 0.7886, 0.7809,\n",
      "        0.5644], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 1, 3, 1, 3, 3, 3, 3, 3, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9816, 0.9706, 0.9983, 0.9112, 0.8111, 0.9897, 0.9935, 1.0000, 0.9927,\n",
      "        0.8331], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.5012, 0.6802, 0.8290, 0.8918, 0.7159, 0.6475, 0.9543, 0.9740, 0.9972,\n",
      "        0.5615], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 1, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8859, 0.9694, 0.7204, 0.4843, 0.4820, 0.6273, 0.9435, 0.5328, 0.9438,\n",
      "        0.9250], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 1, 3, 0, 1, 0, 3, 1, 2, 3], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9808, 0.9086, 0.7916, 0.9361, 0.9991, 0.8507, 0.8711, 0.7283, 0.9718,\n",
      "        0.8081], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.4311, 0.9111, 0.8326, 0.8435, 0.9798, 0.8213, 0.8305, 0.3583, 0.9988,\n",
      "        0.5339], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 1, 1, 2, 3, 2, 3, 3, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9835, 0.8850, 0.9877, 0.9773, 0.9971, 0.5495, 0.7232, 0.9545, 0.6231,\n",
      "        0.7364], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 0, 1, 3, 2, 3, 3, 3, 3, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9155, 0.4411, 0.7166, 0.8480, 0.7868, 0.9389, 0.7413, 0.9106, 0.5955,\n",
      "        0.6838], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 0, 2, 3, 2, 2, 3, 3, 3, 2], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.5352, 0.9980, 0.9845, 0.9695, 0.8089, 0.9500, 0.9797, 0.8942, 0.6102,\n",
      "        0.9743], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 3, 1, 1, 3, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9955, 0.9736, 1.0000, 0.9673, 0.6436, 0.6402, 0.8637, 0.8870, 0.6610,\n",
      "        0.9945], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 3, 1, 1, 3, 3, 1, 3, 1, 3], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9770, 0.8430, 0.9971, 0.8651, 0.8764, 0.9865, 0.9744, 0.9421, 0.9193,\n",
      "        0.9664], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 0, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9845, 0.9006, 0.9902, 0.9998, 0.9852, 0.9987, 0.9770, 0.8816, 0.9596,\n",
      "        0.9977], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9556, 0.7790, 1.0000, 0.9669, 0.9999, 0.9993, 0.8134, 0.8180, 0.9214,\n",
      "        0.7190], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 3, 3, 1, 1], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9985, 1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9997, 0.9996, 1.0000, 0.9987, 1.0000, 0.9999, 0.7559, 0.9965, 0.5398,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 2, 2, 1, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9990, 1.0000, 0.9991, 0.9998, 0.9935,\n",
      "        0.9999], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9961, 0.9999, 1.0000, 0.9998, 1.0000, 0.9976, 1.0000, 0.9933, 1.0000,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9044, 0.9961, 0.9143, 1.0000, 0.9997, 0.9408, 0.3667, 0.8365, 0.7739,\n",
      "        0.6865], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 2, 3, 3, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 0.9267, 0.9820, 0.8802, 0.5716, 0.8647, 0.5834, 0.8388, 0.6059,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 3, 3, 3, 2, 3, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9984, 0.9977, 0.4848, 0.4804, 0.5988, 0.7531, 0.6175, 0.9895, 0.9782,\n",
      "        0.7663], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 1, 1, 2, 1, 2, 2, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 0.7443, 0.9969, 0.4877, 0.8015, 0.9883, 0.9839, 0.9774, 0.6823,\n",
      "        0.9434], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 3, 3, 3, 2, 3, 3, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9978, 0.9899, 0.8044, 0.7081, 0.9117, 0.8937, 0.7320, 0.3892, 0.4516,\n",
      "        0.8383], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 3, 3, 3, 0, 2, 0, 3, 1, 1], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7957, 0.5037, 0.8722, 0.9624, 0.7200, 0.8899, 0.9984, 0.9044, 0.9457,\n",
      "        0.8153], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 2, 2, 3, 2, 2, 2, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9641, 0.9998, 0.9746, 1.0000, 0.9992, 0.9995, 0.9969, 0.8714, 0.9999,\n",
      "        0.9988], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.4666, 0.9669, 0.9902, 0.7985, 0.9628, 0.3855, 0.9670, 0.5903, 0.9979,\n",
      "        0.9823], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 2, 2, 2, 2, 2, 2, 3, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9603, 0.8712, 0.9512, 0.8957, 0.9627, 0.3867, 0.9797, 0.8634, 0.5715,\n",
      "        0.9249], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 2, 2, 2, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 0.9999, 1.0000, 0.8271, 0.6725, 0.8889, 0.9966, 0.9428, 1.0000,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 1, 2, 2, 2, 2, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9911, 0.9978, 0.7990, 1.0000, 0.9977, 0.9608, 0.9999, 0.8335, 1.0000,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 0.9995, 0.4787, 0.9842, 0.6343, 0.9813, 1.0000, 1.0000, 0.9905,\n",
      "        0.9932], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 3, 2, 2, 3, 2, 2, 2, 2], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 0.9990, 0.3079, 0.3616,\n",
      "        0.5539], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 2, 2, 2, 2, 2, 2, 0, 1, 1], device='cuda:0'))\n",
      "tensor([2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9430, 0.9892, 0.9949, 0.9997, 0.8049, 0.9985, 0.9954, 0.9731, 0.6317,\n",
      "        0.6042], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 1, 3, 3, 3, 2], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8414, 0.9988, 0.6295, 0.9761, 0.8875, 0.7175, 0.8230, 0.5884, 0.9862,\n",
      "        0.8853], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 1, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9256, 0.4138, 0.8629, 0.5807, 0.5316, 0.9649, 0.8701, 0.9511, 0.9994,\n",
      "        0.9786], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 1, 3, 1, 1, 3, 1, 3, 3, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8733, 0.9334, 0.7213, 0.5700, 0.5675, 0.6939, 0.9105, 0.7621, 0.6182,\n",
      "        0.8211], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 1, 1, 1, 1, 1, 1, 3, 2], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.6877, 0.9328, 0.9451, 0.5692, 0.7866, 0.6114, 0.9993, 0.9955, 0.9474,\n",
      "        0.5186], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 1, 1, 1, 3, 3, 3, 1], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9904, 1.0000, 1.0000, 1.0000, 1.0000, 0.9955, 1.0000, 0.9992, 0.9976,\n",
      "        0.9999], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 0.9981, 1.0000, 0.9940, 0.9998, 0.9999, 1.0000, 0.9993, 0.9978,\n",
      "        0.9225], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8897, 0.6012, 0.9898, 0.6606, 0.9886, 0.5440, 0.9958, 0.5875, 0.9199,\n",
      "        0.9931], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 1, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8468, 0.9111, 0.9985, 0.9961, 0.9996, 0.8472, 0.9514, 0.4920, 0.9144,\n",
      "        0.9993], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 3, 3, 1, 1, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.6072, 0.9516, 0.5828, 0.8017, 0.9469, 0.8785, 0.6650, 0.9708, 0.9999,\n",
      "        0.9852], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 2, 1, 1, 1, 3, 3, 1, 1], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.5816, 0.6891, 0.8697, 0.4686, 0.9585, 0.6530, 0.9115, 0.7205, 0.5619,\n",
      "        0.9772], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 0, 0, 0, 1, 3, 1, 1, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9579, 0.8786, 0.9914, 0.6638, 0.8660, 0.8735, 0.9878, 0.5435, 0.5508,\n",
      "        0.9908], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 1, 3, 3, 1, 1], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9898, 0.6213, 0.9978, 0.9827, 0.6610, 0.9996, 0.8935, 0.9999, 0.6253,\n",
      "        0.9989], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 3, 3, 3, 1, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9948, 1.0000, 0.6544, 1.0000, 0.9998, 0.9917, 0.9959, 0.9999, 0.9592,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 1, 3, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.4900, 0.5414, 0.5892, 0.5216, 0.9989, 0.8731, 0.9592, 0.9994, 0.8875,\n",
      "        0.9841], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 3, 3, 1, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9998, 0.9999, 1.0000, 1.0000, 0.9937, 1.0000, 0.9999, 0.9999, 0.9853,\n",
      "        0.9997], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7298, 0.6088, 0.3476, 0.5745, 0.6947, 0.9261, 0.9594, 0.7363, 0.4865,\n",
      "        0.7068], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 1, 3, 1, 1, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7966, 0.8995, 0.8077, 0.7400, 0.9530, 0.9823, 0.9985, 0.9687, 0.6646,\n",
      "        0.8829], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0'))\n",
      "tensor([3, 3, 3, 3, 3, 3, 3, 3, 3, 3], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8994, 0.5668, 0.8385, 0.9994, 0.4751, 0.7624, 0.9453, 0.4976, 0.9982,\n",
      "        0.9851], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([2, 1, 0, 0, 3, 1, 1, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9916, 0.5444, 0.9484, 0.9961, 0.9572, 0.9913, 0.9997, 0.6851, 0.5987,\n",
      "        0.8879], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 0, 0, 0, 0, 0, 0, 0, 3, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9890, 0.6974, 0.9987, 0.9999, 0.7708, 0.9712, 0.9974, 0.9913, 1.0000,\n",
      "        0.9927], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9998, 0.9868, 1.0000, 0.9988, 0.9994, 0.9924, 1.0000, 1.0000, 0.8834,\n",
      "        0.8774], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999, 1.0000, 1.0000, 1.0000, 0.9999,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 0.9852, 0.9999, 1.0000, 1.0000, 0.9915, 0.9994, 1.0000, 0.9996,\n",
      "        0.9998], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 0.9995, 0.9820, 1.0000, 1.0000, 0.9997, 1.0000, 0.9994, 1.0000,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([1.0000, 1.0000, 1.0000, 0.9991, 0.9941, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9948, 1.0000, 0.9951, 0.9924, 0.9999, 0.9992, 0.9672, 0.9843, 0.9989,\n",
      "        1.0000], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7827, 0.5459, 0.5273, 0.6874, 0.9499, 0.8646, 0.9238, 0.9875, 0.9977,\n",
      "        0.9894], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 1, 1, 3, 0, 3, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.6669, 0.6942, 0.6761, 0.5223, 0.6858, 0.9945, 0.6210, 0.7546, 0.5311,\n",
      "        0.7067], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([1, 1, 0, 1, 0, 0, 1, 1, 3, 1], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8811, 0.9992, 0.9343, 0.4949, 0.5398, 0.9296, 0.9281, 0.8240, 0.8252,\n",
      "        0.9922], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 1, 1, 0, 1, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.5262, 1.0000, 0.9751, 0.8865, 0.9990, 0.7197, 0.9666, 0.7502, 0.9997,\n",
      "        0.7898], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 1, 0, 0, 0, 3], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7313, 0.5197, 0.7590, 0.9324, 0.7881, 0.9449, 0.8734, 0.7088, 0.8727,\n",
      "        0.9588], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([3, 0, 0, 0, 0, 0, 1, 1, 1, 1], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.8034, 1.0000, 0.9998, 0.9958, 0.9992, 0.9109, 0.5632, 0.9683, 0.5656,\n",
      "        0.9821], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.7344, 0.9856, 0.4884, 0.9997, 0.9984, 0.9992, 0.6105, 0.9998, 0.9329,\n",
      "        0.5408], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 3], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9809, 0.7666, 0.9632, 0.9943, 0.5466, 0.9999, 0.9856, 0.8919, 0.9786,\n",
      "        0.7351], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 2, 0, 0, 1, 0, 0, 2, 2, 3], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n",
      "torch.return_types.max(\n",
      "values=tensor([0.9886, 0.9999, 0.9999, 0.9982, 1.0000, 0.9988, 1.0000, 0.5974, 0.8459,\n",
      "        0.7922], device='cuda:0', grad_fn=<MaxBackward0>),\n",
      "indices=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0', dtype=torch.uint8)\n"
     ]
    }
   ],
   "source": [
    "for data, targets in data_loader_test:\n",
    "    data=data[0].to(device)\n",
    "    log_ps = model(data[:,:3])\n",
    "    # Convert to probabilities\n",
    "    ps = torch.exp(log_ps)\n",
    "        # Find predictions and correct\n",
    "    pred = torch.max(ps, dim=1)\n",
    "    print(pred)\n",
    "    targets = targets[0].to(device)\n",
    "    print(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy of vggnet16 model on the test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on all 16 Test Set videos: 70 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in data_loader_test:\n",
    "        images, labels = data\n",
    "        outputs = model(images[0][:,:3])\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels[0].size(0)\n",
    "        label = labels[0].to(device)\n",
    "        predicted = predicted.to(device)\n",
    "        correct += (predicted == label).sum().item()\n",
    "\n",
    "print('Accuracy of the network on all 16 Test Set videos: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
